# -*- coding: utf-8 -*-
"""Lab_8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ysrTYAlaUqWfszYYQXzFEJOfXFYfcg_v
"""

import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer

vocab_size = 10000
max_length = 200
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)
x_train = pad_sequences(x_train, maxlen=max_length)
x_test = pad_sequences(x_test, maxlen=max_length)
model = Sequential([
 Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length),
 SimpleRNN(128, activation='tanh', return_sequences=False),
 Dropout(0.5),
 Dense(64, activation='relu'),
 Dropout(0.5),
 Dense(1, activation='sigmoid')
])
model.compile(optimizer='adam',
 loss='binary_crossentropy',
 metrics=['accuracy'])
history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))
test_loss, test_accuracy = model.evaluate(x_test, y_test)
print(f"Test Accuracy: {test_accuracy:.2f}")
sample_review = "This movie was fantastic! The characters were well-developed and the plot was thrilling."


tokenizer = imdb.get_word_index()
reverse_word_index = {value: key for (key, value) in tokenizer.items()}
encoded_review = [tokenizer.get(word, 2) for word in sample_review.lower().split()]
padded_review = pad_sequences([encoded_review], maxlen=max_length)

prediction = model.predict(padded_review)
sentiment = "Positive" if prediction[0] > 0.5 else "Negative"
print(f"Predicted Sentiment: {sentiment}")

